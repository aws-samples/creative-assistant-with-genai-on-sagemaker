{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c6d30b8",
   "metadata": {},
   "source": [
    "## Setup for Magic Fill/Replace Models\n",
    "\n",
    "---\n",
    "In this notebook, you are going to run a defined setup process for our magic fill/replace solution. Due to the size of the models, some of the step may take some time to complete. The entire notebook should finish within 1 hour. At the end of the notebook run, we should have a instended inference container in Elastic Container Registry (ECR) ready to host our models using SageMaker Endpoint (MME).\n",
    "\n",
    "SageMaker MME is a service provided by Amazon SageMaker that allows multiple machine learning models to be hosted on a single endpoint. This means that multiple models can be deployed and managed together, making it easier to scale and maintain machine learning applications. With a multi-model endpoint, different models can be selected based on specific needs, allowing for more flexibility and efficiency. It also enables different types of models to be combined, such as computer vision and natural language processing models, to create more comprehensive applications.\n",
    "\n",
    "Here is a high level breakdown of the setup steps:\n",
    "\n",
    "1. Downloading pre-trained models\n",
    "2. Package conda environment for additional model dependencies\n",
    "3. Extend SageMaker managed Triton container with model checkpoints and conda packs pre-loaded\n",
    "4. Push the container to AWS Elastic Container Registry (ECR)\n",
    "\n",
    "---\n",
    "\n",
    "This notebook will locally build a custom docker image. **We recommend to use pytorch kernel on SageMaker Notebook Instance using `ml.g4dn.xlarge`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa94952",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq sagemaker transformers accelerate diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d847c11",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20dd151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import diffusers\n",
    "import torch \n",
    "\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto3.Session())\n",
    "region = sagemaker_session.boto_region_name\n",
    "account = sagemaker_session.account_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc64c6",
   "metadata": {},
   "source": [
    "### Download Pre-trained Models\n",
    "#### Download and Package SAM Checkpoint\n",
    "**Apache-2.0 license**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f957660",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_file_name = \"sam_vit_h_4b8939.pth\"\n",
    "download_path = f\"https://huggingface.co/spaces/abhishek/StableSAM/resolve/main/{model_file_name}\"\n",
    "\n",
    "!wget $download_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c890242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_tar = f\"docker/{model_file_name}.tar.gz\"\n",
    "\n",
    "def make_tarfile(output_filename, source_dir):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        tar.add(source_dir, arcname=os.path.basename(source_dir))\n",
    "\n",
    "make_tarfile(sd_tar, model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f8fed8",
   "metadata": {},
   "source": [
    "#### Download and Package Satable Diffusion (SD) Inpaint Model\n",
    "**CreativeML Open RAIL++-M License**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43b079",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = diffusers.StableDiffusionInpaintPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-inpainting\",\n",
    "                                                             cache_dir='hf_cache',\n",
    "                                                             torch_dtype=torch.float16)\n",
    "\n",
    "sd_dir = 'stable_diff_inpaint'\n",
    "pipeline.save_pretrained(sd_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ed1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_tar = f\"docker/{sd_dir}.tar.gz\"\n",
    "\n",
    "def make_tarfile(output_filename, source_dir):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        tar.add(source_dir, arcname=os.path.basename(source_dir))\n",
    "\n",
    "make_tarfile(sd_tar, sd_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d27462",
   "metadata": {},
   "source": [
    "#### Downloading Images and Modules from Inpaint Anything\n",
    "**Apache-2.0 license**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649e852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cd statics && wget https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/fill-anything/sample1.png\n",
    "!cd statics && wget https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/remove-anything/dog.jpg\n",
    "!cd statics && wget https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/replace-anything/bus.jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd model_repo/sd_inpaint/1 && wget https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/utils/mask_processing.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca1d1b0",
   "metadata": {},
   "source": [
    "### Package Conda Environment for each model\n",
    "\n",
    "SageMaker NVIDIA Triton container images does not contain all the libraries two run our SAM and SD Inpaint models. However, Triton allows you to bring additional dependencies using conda pack. Let's run the two cells below to create a `xxx_env.tar.gz` environment package for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dbfb78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cd docker && bash sam_conda_dependencies.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030dce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd docker && bash sd_conda_dependencies.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2cc46",
   "metadata": {},
   "source": [
    "### Extend SageMaker Managed Triton Container\n",
    "\n",
    "When we host these models on SageMaker MME. When invoked, model files will be loaded from S3 onto the instance. Due the large size of our models and model packages (SAM: 2.4GB + conda pack: 2.52 GB, LaMa: 0.38 GB + conda pack: 3.35GB), we are going to pre-load these files into the container. This will reduce model loading time and improve user experience during cold start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384782ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# account mapping for SageMaker Triton Image\n",
    "account_id_map = {\n",
    "    \"us-east-1\": \"785573368785\",\n",
    "    \"us-east-2\": \"007439368137\",\n",
    "    \"us-west-1\": \"710691900526\",\n",
    "    \"us-west-2\": \"301217895009\",\n",
    "    \"eu-west-1\": \"802834080501\",\n",
    "    \"eu-west-2\": \"205493899709\",\n",
    "    \"eu-west-3\": \"254080097072\",\n",
    "    \"eu-north-1\": \"601324751636\",\n",
    "    \"eu-south-1\": \"966458181534\",\n",
    "    \"eu-central-1\": \"746233611703\",\n",
    "    \"ap-east-1\": \"110948597952\",\n",
    "    \"ap-south-1\": \"763008648453\",\n",
    "    \"ap-northeast-1\": \"941853720454\",\n",
    "    \"ap-northeast-2\": \"151534178276\",\n",
    "    \"ap-southeast-1\": \"324986816169\",\n",
    "    \"ap-southeast-2\": \"355873309152\",\n",
    "    \"cn-northwest-1\": \"474822919863\",\n",
    "    \"cn-north-1\": \"472730292857\",\n",
    "    \"sa-east-1\": \"756306329178\",\n",
    "    \"ca-central-1\": \"464438896020\",\n",
    "    \"me-south-1\": \"836785723513\",\n",
    "    \"af-south-1\": \"774647643957\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "if region not in account_id_map.keys():\n",
    "    raise (\"UNSUPPORTED REGION\")\n",
    "\n",
    "base = \"amazonaws.com.cn\" if region.startswith(\"cn-\") else \"amazonaws.com\"\n",
    "mme_triton_image_uri = (\n",
    "    \"{account_id}.dkr.ecr.{region}.{base}/sagemaker-tritonserver:22.12-py3\".format(\n",
    "        account_id=account_id_map[region], region=region, base=base\n",
    "    )\n",
    ")\n",
    "triton_account_id = account_id_map[region]\n",
    "mme_triton_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b461e3",
   "metadata": {},
   "source": [
    "Preview the docker file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee4d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat docker/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2cd47",
   "metadata": {},
   "source": [
    "### Build & push the new image to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77881a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New container image name\n",
    "new_image_name = 'sagemaker-tritonserver-sam-sd-inpaint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8833d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture build_output\n",
    "!cd docker && bash build_and_push.sh \"$new_image_name\" \"latest\" \"$mme_triton_image_uri\" \"$region\" \"$account\" \"$triton_account_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e6d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Error response from daemon' in str(build_output):\n",
    "    print(build_output)\n",
    "    raise SystemExit('\\n\\n!!There was an error with the container build!!')\n",
    "else:\n",
    "    extended_triton_image_uri = str(build_output).strip().split('\\n')[-1]\n",
    "    \n",
    "print(f\"New image URI from ECR: {extended_triton_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed8778",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store extended_triton_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0c0add",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
